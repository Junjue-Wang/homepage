<!doctype html>
<html lang="en">
<head>

  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
  <link href="css/main.css" rel="stylesheet">
  <link rel="shortcut icon" href="img/myicon.ico" type="image/x-icon" />
  <title>Junjue Wang's Page</title>
</head>
<body>
<div id="main_div" class="bg-light text-dark">
  <div class="bio">
    <div class="row">
      <div class="col-md-12">
          <table>
            <tbody>
                <tr>
                  <td width="150px">
                    <p align="center">
                      <img src="img/photo.jpg" style="width: 100%">
                    </p>
                  </td>
                  <td style="float: left; margin-left: 20px">
                      <h2>Junjue Wang 王俊珏</h2>
                      <h5>PhD Student</h5>
                      <h5>LIESMARS, Wuhan University, Hubei, China</h5>
                      <h5>E-mail: kingdrone@whu.edu.cn</h5>
                    <div style="margin-top:10px">
                      <a href="https://www.researchgate.net/profile/Junjue_Wang2"><img src="img/researchgate.png" height="32" width="32" ></a>
                      <a href="https://scholar.google.com/citations?hl=zh-CN&user=H58gKSAAAAAJ"><img src="img/google_sch.png" height="32" width="32"/></a>
                      <a href="https://orcid.org/0000-0002-9500-3399"><img src="img/orcid.png" height="32" width="32"/></a>
                      <a href="https://github.com/Junjue-Wang"><img src="img/github.png" height="32" width="32"/></a>
                    </div>
                  </td>
                </tr>
            </tbody>
          </table>
      </div>

      <div class="col-md-12" style="margin-top: 20px">
        <p>I am a PhD student of photogrammetry and remote sensing at State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing (LIESMARS), Wuhan University.
          I'm now a member of <a href="http://rsidea.whu.edu.cn/">RSIDEA group</a>, advised by Prof. <a href="http://rsidea.whu.edu.cn/">Yanfei Zhong</a> and <a href="http://www.lmars.whu.edu.cn/prof_web/zhangliangpei/rs/index.html">Liangpei Zhang</a>.
        </p>
        <p>
          My major research interests are high-resolution
          remote sensing imagery semantic segmentation and
          computer vision.
        </p>
<!--        <p>-->
<!--          E-mail: kingdrone@whu.edu.cn </br>-->
<!--          QQ: 617382870-->
<!--        </p>-->
      </div>

    </div>


  <div class="row">
    <div class="col-md-12">
      <h2>Recent News</h2>
      <p><b>[2022.07]</b> Our <a href="https://github.com/Junjue-Wang/CapFormer">CapFormer</a> has become Top10 in IGARSS 2022 Student Paper Contest.</p>
      <p><b>[2022.06]</b> We won 1<sup>st</sup> Place in <a href="https://www.iarai.ac.at/landslide4sense/challenge/">2022 IJCAI LandSlideSense Challenge</a>.</p>
      <p><b>[2022.05]</b> <a href="https://www.researchgate.net/publication/360484883_Cross-sensor_domain_adaptation_for_high_spatial_resolution_urban_land-cover_mapping_From_airborne_to_spaceborne_imagery">LoveCS</a> was accepted by RSE'2022 and code was released <a href="https://github.com/Junjue-Wang/LoveCS">here</a>.</p>
      <p><b>[2022.03]</b> We won 1<sup>st</sup> Place (1/1149) in <a href="https://tianchi.aliyun.com/competition/entrance/531945/tab/292">2022 Ali Tianchi Real World Image Forgery Localization Challenge</a> and the solution was shared <a href="https://github.com/Junjue-Wang/Rank1-Ali-Tianchi-Real-Scene-Tampering-Image-Detection-Challenge">here</a>.</p>
      <p><b>[2022.03]</b> Our <a href="https://www.researchgate.net/publication/342105878_RSNet_The_Search_for_Remote_Sensing_Deep_Neural_Networks_in_Recognition_Tasks?_sg=ygVHXE0RkN6ek8wXl_qQzSD7qCabtSpXYfukmQ7zgnCk5Ic7gO2C1RAe8O8Hho4PUXnvgmh-qpxM8GJEeDV75n-kEB_v5qn542f9gYlp.ndm2Tkvcf8NsDMmsvZb5_CaFMRjr100VWDiPkiLHfe_QtHvNKAAeQnuCLtuRSfZya1ZFOU-sI8-gPjVMg-4J4Q">RSNet</a> has become ESI highly cited paper (Top 1%). </p>
      <p><b>[2021.10]</b> <a href="https://codalab.lisn.upsaclay.fr/competitions/421">LoveDA Semantic Segmentation</a> and <a href="https://codalab.lisn.upsaclay.fr/competitions/424">Unsupervised Domain Adaptation</a> Contests are held on Codalab.</p>
<!--      <p><b>[2021.10]</b> The Code and Dataset of LoveDA (NeurIPS'2021) are released  <a href="https://github.com/Junjue-Wang/LoveDA">here</a>.</p>-->
<!--      <p><b>[2021.10]</b> The Code of FactSeg (TGRS'2021) is released  <a href="https://github.com/Junjue-Wang/FactSeg">here</a>.</p>-->
<!--      <p><b>[2021.09]</b> The FactSeg is accepted by TGRS.</p>-->
<!--      <p><b>[2021.03]</b> Our team win the 4th place in 2021 IEEE GRSS Data Fusion Contest, Track: Multitemporal Semantic Change Detection.</p>-->
    </div>

    <div class="col-md-12">
      <h2>Selected Publications</h2>
      <div class="article_content">
        <p class="article_title">Cross-sensor domain adaptation for high spatial resolution urban land-cover mapping: From airborne to spaceborne imagery</p>
        <p class="article_author"><b>Junjue Wang</b>, Ailong Ma, Yanfei Zhong, Zhuo Zheng, Liangpei Zhang</p>
        <p class="article_journal">Remote Sensing of Environment (RSE), 2022</p>
        <div class="flex-shrink-0">
          <a href="https://www.researchgate.net/publication/360484883_Cross-sensor_domain_adaptation_for_high_spatial_resolution_urban_land-cover_mapping_From_airborne_to_spaceborne_imagery">Paper</a>
          &nbsp;
          <a href="https://github.com/Junjue-Wang/LoveCS">Code</a>
          &nbsp;
          <a href="https://pan.baidu.com/s/1YnsMFDOMBGO-oz_PAUkuFQ?pwd=2333">Product</a>
        </div>
      </div>


      <div class="article_content">
        <p class="article_title">LoveDA: A Remote Sensing Land-Cover Dataset for Domain Adaptive Semantic Segmentation</p>
        <p class="article_author"><b>Junjue Wang</b>, Zhuo Zheng, Ailong Ma, Yanfei Zhong</p>
        <p class="article_journal">Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (NeurIPS), 2021</p>
        <div class="flex-shrink-0">
          <a href="https://www.researchgate.net/publication/355390292_LoveDA_A_Remote_Sensing_Land-Cover_Dataset_for_Domain_Adaptive_Semantic_Segmentation?_sg%5B0%5D=6wXVE-p1zxMXGPBlbejDqXjV8tsg0MXN71kPrxezXyRgQm02D3OciHvMpt_wQZ_ydXife2rUkXEaPGBWFmJLx39uCAVN6xj7sn5UfqlQ.Ey_uv26Ax71LzLalgYHKtHduCMuqDBT8aAFpKwEOPtQCqyZICYariQGxpTpSwbavprpk8e2MWTyU9Po7cEFHSw">Paper</a>
          &nbsp;
          <a href="https://github.com/Junjue-Wang/LoveDA">Code</a>
          &nbsp;
          <a href="https://zenodo.org/record/5706578#.Yi2m1-hByUk">Data</a>
        </div>
      </div>

      <div class="article_content">
        <p class="article_title">FactSeg: Foreground Activation Driven Small Object Semantic
          Segmentation in Large-Scale Remote Sensing Imagery</p>
        <p class="article_author">Ailong Ma, <b>Junjue Wang</b>, Yanfei Zhong, Zhuo Zheng</p>
        <p class="article_journal">IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2022</p>
        <div class="flex-shrink-0">
          <a href="https://www.researchgate.net/publication/353357122_FactSeg_Foreground_Activation_Driven_Small_Object_Semantic_Segmentation_in_Large-Scale_Remote_Sensing_Imagery">Paper</a>
          &nbsp;
          <a href="https://github.com/Junjue-Wang/FactSeg">Code</a>
        </div>
      </div>


      <div class="article_content">
          <p class="article_title">RSNet: The Search for Remote Sensing Deep
            Neural Networks in Recognition Tasks</p>
          <p class="article_author"><b>Junjue Wang</b>, Yanfei Zhong, Zhuo Zheng, Ailong Ma, Liangpei Zhang</p>
          <p class="article_journal">IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2021</p>
          <div class="flex-shrink-0"><a href="https://www.researchgate.net/publication/342105878_RSNet_The_Search_for_Remote_Sensing_Deep_Neural_Networks_in_Recognition_Tasks?_sg=ygVHXE0RkN6ek8wXl_qQzSD7qCabtSpXYfukmQ7zgnCk5Ic7gO2C1RAe8O8Hho4PUXnvgmh-qpxM8GJEeDV75n-kEB_v5qn542f9gYlp.ndm2Tkvcf8NsDMmsvZb5_CaFMRjr100VWDiPkiLHfe_QtHvNKAAeQnuCLtuRSfZya1ZFOU-sI8-gPjVMg-4J4Q">Paper</a></div>
      </div>


<!--      <div class="article_content">-->
<!--        <p class="article_title">SceneNet: Remote sensing scene classification deep learning-->
<!--          network using multi-objective neural evolution architecture search</p>-->
<!--        <p class="article_author">Ailong Ma, Yuting Wan, Yanfei Zhong, <b>Junjue Wang</b>, Liangpei Zhang</p>-->
<!--        <p class="article_journal">ISPRS Journal of Photogrammetry and Remote Sensing (ISPRS), 2021</p>-->
<!--        <div class="flex-shrink-0"><a href="https://www.researchgate.net/publication/348354783_SceneNet_Remote_sensing_scene_classification_deep_learning_network_using_multi-objective_neural_evolution_architecture_search">Paper</a></div>-->
<!--      </div>-->

      <div class="article_content">
        <p class="article_title">Foreground-Aware Relation Network for Geospatial Object Segmentation in High Spatial Resolution Remote Sensing Imagery</p>
        <p class="article_author">Zhuo Zheng, Yanfei Zhong, <b>Junjue Wang</b>, Ailong Ma</p>
        <p class="article_journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020</p>
        <div class="flex-shrink-0">
          <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Zheng_Foreground-Aware_Relation_Network_for_Geospatial_Object_Segmentation_in_High_Spatial_CVPR_2020_paper.pdf">Paper</a>

          <a href="https://github.com/Z-Zheng/FarSeg">Code</a>
        </div>
      </div>

    </div>




    <div class="col-md-12">
      <h2>Award</h2>
      <div class="article_content">
        <p><b>[2022.4-2022.6]</b></p>
        <p class="article_title">2022 IJCAI LandSlide4Sense CDCEO workshop Challenge</p>
        <div class="article_journal">
          <p><i class="fas fa-trophy text-warning"></i>
            1<sup>st</sup> Place</p></div>
        <div class="flex-shrink-0"><a href="https://www.iarai.ac.at/landslide4sense/challenge/">Website</a>
          &nbsp;
          <a href="https://youtu.be/SiBjK9cOOB0">Paper</a>
          &nbsp;
        </div>
      </div>
      <div class="article_content">
        <p><b>[2022.2-2022.3]</b></p>
        <p class="article_title">2022 Ali Tianchi Real World Image Forgery Localization Challenge</p>
        <div class="article_journal">
          <p><i class="fas fa-trophy text-warning"></i>
            1<sup>st</sup> Place (1/1149)</p></div>
        <div class="flex-shrink-0"><a href="https://tianchi.aliyun.com/competition/entrance/531945/tab/292">Website</a>
          &nbsp;
          <a href="https://github.com/Junjue-Wang/Rank1-Ali-Tianchi-Real-Scene-Tampering-Image-Detection-Challenge">Solution</a>
          &nbsp;
        </div>
      </div>
      <div class="article_content">
        <p><b>[2020.10-2020.12]</b></p>
        <p class="article_title">2021 IEEE GRSS Data Fusion Contest, Track: Multitemporal Semantic Change Detection</p>
        <div class="article_journal">
          <p><i class="fas fa-trophy text-warning"></i>
            4<sup>th</sup> Place</p></div>
        <div class="flex-shrink-0">
          <a href="https://www.grss-ieee.org/community/technical-committees/2021-ieee-grss-data-fusion-contest-track-msd/">Website</a>
          &nbsp;
          <a href="https://www.grss-ieee.org/community/technical-committees/2021-ieee-grss-data-fusion-contest-results/">Announcement</a>
        </div>
      </div>

      <div class="article_content">
        <p><b>[2020.03-2020.05]</b></p>
        <p class="article_title">SpaceNet 6 EarthVision workshop challenge at CVPR 2020</p>
        <div class="article_journal">
          <p><i class="fas fa-trophy text-warning"></i>
             Top Graduate Award (__EVER__)</p></div>
        <div class="flex-shrink-0">
          <a href="https://spacenet.ai/sn6-challenge/">Website</a>
          &nbsp;
          <a href="https://medium.com/the-downlinq/spacenet-6-announcing-the-winners-df817712b515">Announcement</a>
          &nbsp;
          <a href="https://www.topcoder.com/challenges/30116975?tab=submissions">Leaderboard</a>

        </div>
      </div>

    <div class="article_content">
      <p><b>[2019.10-2019.12]</b></p>
      <p class="article_title">xView2 Challenge</p>
      <div class="article_journal">
        <p><i class="fas fa-trophy text-warning"></i>
          4<sup>th</sup> Place (4/3500+), overall</p></div>
      <div class="flex-shrink-0"><a href="https://spacenet.ai/sn6-challenge/">Website</a>
        &nbsp;
        <a href="https://xview2.org/challenge">Announcement</a>
        &nbsp;
        <a href="https://github.com/DIUx-xView/xView2_fourth_place">Code</a>
      </div>
    </div>

    <div class="article_content">
      <p><b>[2019.10-2019.12]</b></p>
      <p class="article_title">2019 IEEE GRSS Data Fusion Contest, Single-view Semantic 3D Challenge</p>
      <div class="article_journal">
        <p><i class="fas fa-trophy text-warning"></i>
          2<sup>nd</sup> Place (2/400+)</p></div>
      <div class="flex-shrink-0"><a href="https://spacenet.ai/sn6-challenge/">Website</a>
        &nbsp;
        <a href="http://www.grss-ieee.org/community/technical-committees/data-fusion/2019-ieee-grss-data-fusion-contest-results/">Announcement</a>
        &nbsp;
        <a href="https://ieeexplore.ieee.org/abstract/document/8897927">Paper</a>
      </div>
    </div>

<!--      <div class="article_content">-->
<!--        <p><b>[2019.06-2019.08]</b></p>-->
<!--        <p class="article_title">2019 County Agricultural Brain AI Challenge</p>-->
<!--        <div class="article_journal">-->
<!--          <p><i class="bi bi-trophy-fill"></i>-->
<!--            18<sup>th</sup> Place (18/1520) (seed_2333)</p></div>-->
<!--        <div class="flex-shrink-0"><a href="https://spacenet.ai/sn6-challenge/">Website</a>-->
<!--          &nbsp;-->
<!--          <a href="https://tianchi.aliyun.com/competition/entrance/231717/introduction">Website</a>-->
<!--          &nbsp;-->
<!--          <a href="https://tianchi.aliyun.com/competition/entrance/231717/rankingList">Leaderboard</a>-->
<!--        </div>-->
<!--      </div>-->
    </div>

    <div class="row">
      <div class="col-md-12">
        <h2>Academic Service</h2>
        <div class="article_content">
          <b>Journal Reviewer</b></br>
          IEEE TGRS, Visual Computer
          </br>
          <b>Conference Reviewer</b></br>
          NeurIPS 2021, 2022
          </div>
        </div>

      </div>
    </div>

    <div class="col-md-12" style="text-align: left">
      <a href="https://info.flagcounter.com/cNI0"><img src="https://s04.flagcounter.com/map/cNI0/size_s/txt_000000/border_CCCCCC/pageviews_1/viewers_0/flags_0/" alt="Flag Counter" rel="unfollow"></a>

      <a href="https://info.flagcounter.com/THRk"><img src="https://s01.flagcounter.com/count2/THRk/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_0/flags_0/percent_0/" alt="Flag Counter" rel="unfollow" style="vertical-align:top"></a>
    </div>

  </div>

</div>






<!-- Optional JavaScript; choose one of the two! -->

<!-- Option 1: Bootstrap Bundle with Popper -->
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>

<!-- Option 2: Separate Popper and Bootstrap JS -->
<!--
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js" integrity="sha384-7+zCNj/IqJ95wo16oMtfsKbZ9ccEh31eOz1HGyDuCQ6wgnyJNSYdrPa03rtR1zdB" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js" integrity="sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5/YESvpZ13" crossorigin="anonymous"></script>
-->



</body>
</html>
